Parfait. Voici le prompt Replit focalis√© uniquement sur l‚ÄôIA (am√©lioration profonde des annonces, standardisation, suggestions prix/d√©lais, LOC uplift, sourcing web ‚Äú√©co‚Äù, int√©gration scoring, explicabilit√©, tests). Aucun r√©glage Preview.

‚∏ª

üß† PROMPT REPLIT ‚Äî IA d‚Äôam√©lioration d‚Äôannonces + Standardisation + Sourcing ‚Äú√©co‚Äù + Int√©gration Scoring (sans preview)

Tu es un assistant IA full‚Äëstack.
Dans mon repo, am√©liore le moteur IA pour qu‚Äôil fournisse une version am√©lior√©e, exploitable et mesurable des annonces publi√©es : r√©√©criture/standardisation, suggestions prix/d√©lais, LOC uplift, questions manquantes, sourcing web ‚Äú√©co‚Äù (gratuit, sans API payantes par d√©faut), int√©gration au scoring et √† la mise en relation. Livre code, migrations, tests, doc. (Ignore tout ce qui concerne le Preview.)

‚∏ª

0) Contraintes & mode ‚Äú√©co‚Äù
	‚Ä¢	Par d√©faut : pas d‚ÄôAPI payantes. D√©couverte via RSS/Sitemap + crawler conforme (robots.txt, rate‚Äëlimit, ETag).
	‚Ä¢	Flags ENV :

FEATURE_STANDARDIZE=true
FEATURE_SOURCING=true
FEATURE_API_CONNECTORS=false   # pourra passer √† true plus tard
BM25_ENABLED=true
EMBEDDINGS_ENABLED=false
DOMAIN_WHITELIST="*.gouv.fr, *.cci.fr, *.github.io, *.notion.site, *.wordpress.com"
RATE_LIMIT_GLOBAL_RPS=2
RATE_LIMIT_PER_DOMAIN_RPS=1
USER_AGENT="MarketplaceBot/0.1 (+contact@exemple.fr)"



‚∏ª

1) Sch√©ma DB (Prisma) ‚Äî ajouts
	‚Ä¢	ProjectStandardization
project_id FK, title_std, summary_std, acceptance_criteria text[],
category_std, sub_category_std, tags_std string[],
tasks_std jsonb[], deliverables_std jsonb[],
skills_std string[], constraints_std string[],
brief_quality_score float, richness_score float,
missing_info jsonb[],
price_suggested_min/med/max int, delay_suggested_days int,
loc_base float, loc_uplift_reco jsonb,
rewrite_version string, timestamps.
	‚Ä¢	WebSource, WebDoc, ExternalCompany, ExternalCompanySignal, SourcingMatch
(comme d√©fini pr√©c√©demment : URL unique, meta, skills[], signals PRICE/PORTFOLIO‚Ä¶, lead_score, reasons, status).

Migrations + index (btree + GIN) fournis.

‚∏ª

2) Microservice ML (FastAPI) ‚Äî modules IA

Cr√©er/renforcer apps/ml/ :
	‚Ä¢	text_normalizer.py : nettoyage FR, normalisation unit√©s (m¬≤, h, pages, km), extraction quantit√©s/contraintes (on‚Äësite/remote).
	‚Ä¢	taxonomizer.py : mapping category_std/sub_category_std/skills_std/tags_std (r√®gles + BM25).
	‚Ä¢	template_rewriter.py : g√©n√©ration offline (templates) : title_std, summary_std (5‚Äì7 phrases), acceptance_criteria (SMART).
	‚Ä¢	brief_quality.py : brief_quality_score, richness_score, missing_info (questions concr√®tes).
	‚Ä¢	price_time_suggester.py : price_suggested_{min,med,max}, delay_suggested_days, rationale (PRM quantiles + ajustements qualit√©/on‚Äësite/raret√©/market_heat).
	‚Ä¢	loc_uplift.py : calcule loc_base et propose {new_budget,new_delay,delta_loc}.
	‚Ä¢	Sourcing √©co :
	‚Ä¢	connectors/rss_sitemap.py (d√©couverte),
	‚Ä¢	crawler/fetcher.py (ETag/Last‚ÄëModified + robots),
	‚Ä¢	parser/reader.py (Readability),
	‚Ä¢	extractors/company.py (nom, email RFC, tel E.164, adresse, NAF si pr√©sent),
	‚Ä¢	enrich/skills_bm25.py, enrich/price_signals.py, enrich/geo_lookup.py (CSV CP‚Üîcoords).
	‚Ä¢	scoring/lead.py : SupplierLeadScore + reasons[].

Endpoints ML
	‚Ä¢	POST /improve {project} ‚Üí renvoie standardisation compl√®te + prix/d√©lais + loc + questions + reasons.
	‚Ä¢	POST /brief/recompute {project_id, answers[]} ‚Üí met √† jour standardisation & suggestions.
	‚Ä¢	POST /sourcing/discover {project_id, strategy:'rss|sitemap', max?} ‚Üí pipeline d√©couverte‚Üíextraction‚Üíenrich‚Üíscore.

Chaque r√©ponse inclut breakdown/reasons + model_version.

‚∏ª

3) API (Fastify) ‚Äî actions tangibles

Cr√©er/mettre √† jour :
	‚Ä¢	POST /ai/projects/:id/improve
‚Ü≥ appelle ML /improve, persiste ProjectStandardization, retourne diffs vs original.
	‚Ä¢	GET /ai/projects/:id/preview
‚Ü≥ renvoie : texte r√©√©crit, crit√®res, brief_quality/richness, price_suggested_*, delay_suggested_days, loc_base + loc_uplift_reco, missing_info, diff titre/desc.
	‚Ä¢	POST /ai/projects/:id/brief/complete {answers:[{question_id,value}], apply?:boolean}
‚Ü≥ recalcule standardisation/prix/d√©lais/LOC.
	‚Ä¢	POST /ai/projects/:id/apply {apply_budget:'min'|'med'|'max', apply_delay?:boolean, apply_title?:boolean, apply_summary?:boolean}
‚Ü≥ applique au Project (budget/d√©lais/titre/desc), log dans ProjectChangeLog.
	‚Ä¢	Sourcing (√©co)
	‚Ä¢	POST /sourcing/discover {project_id, strategy:'rss|sitemap', max?}
	‚Ä¢	GET  /sourcing/project/:id/candidates?min_score=0.4&limit=20 ‚Üí ExternalCompany tri√©es par SupplierLeadScore + reasons[].
	‚Ä¢	Candidats unifi√©s
	‚Ä¢	GET /ai/projects/:id/candidates?diversity=true ‚Üí fusion internes (GlobalScore) + externes (SupplierLeadScore normalis√©) avec MMR si demand√©.

OpenAPI FR avec exemples pour toutes les routes.

‚∏ª

4) Int√©gration Scoring (packages/core)
	‚Ä¢	Ajuster le scoring global pour int√©grer la qualit√© du brief :

QualityScore' = QualityScore * (1 + 0.20*(brief_quality_score - 0.5))
FitScore'     = FitScore     * (1 + 0.15*(richness_score      - 0.5))
if missing_info_count > 0: Risk += 0.05; TimeScore -= 0.03


	‚Ä¢	C√¥t√© sourcing :

SupplierLeadScore =
    0.40*FitBM25(project_std.skills_std, company.skills)
  + 0.15*Geo(distance vs onsite_radius or remote_ok)
  + 0.15*PriceAlign(price_signals, project.price_ref)
  + 0.15*ReputationSignal(PORTFOLIO|SERVICES)
  + 0.10*Freshness(last_seen_at)
  - 0.05*RiskPenalty(dup/incoh√©rences)


	‚Ä¢	GET /ai/projects/:id/candidates : retour breakdown + reasons[] (explicabilit√©).

‚∏ª

5) Donn√©es locales /infra/data
	‚Ä¢	cp_city_coords.csv (CP ‚Üî ville ‚Üî lat/lng)
	‚Ä¢	taxonomy_skills_fr.csv (cat√©gories/sous‚Äëcat√©gories/skills)
	‚Ä¢	price_terms_fr.csv (‚Ç¨/h, ‚Ç¨/jour, forfait, ‚Äú√† partir de‚Äù)
Charge ces CSV au d√©marrage des modules concern√©s.

‚∏ª

6) Tests (obligatoires)

Unit (pytest + vitest)
	‚Ä¢	standardisation : normalizer/taxonomizer/template_rewriter/brief_quality/price_time/loc_uplift
	‚Ä¢	sourcing : robots/rate‚Äëlimit/parser/BM25/price_signals/lead_scoring
	‚Ä¢	scoring : QualityScore', FitScore', p√©nalit√©s missing_info

E2E (supertest)
	1.	POST /ai/projects/:id/improve ‚Üí persiste ProjectStandardization, renvoie suggestions + questions.
	2.	GET /ai/projects/:id/preview ‚Üí montre diffs + scores.
	3.	POST /ai/projects/:id/apply (budget=med + delay + title/summary) ‚Üí Project modifi√© + ProjectChangeLog.
	4.	POST /sourcing/discover ‚Üí GET /sourcing/project/:id/candidates ‚Üí ‚â•1 candidat avec SupplierLeadScore.
	5.	GET /ai/projects/:id/candidates?diversity=true ‚Üí fusion interne+externe + MMR.

Couverture ‚â•80% sur core IA standardisation + sourcing + scoring.

‚∏ª

7) README (FR)
	‚Ä¢	‚ÄúUtiliser l‚ÄôIA d‚Äôam√©lioration‚Äù :
	1.	POST /ai/projects/:id/improve
	2.	GET  /ai/projects/:id/preview
	3.	POST /ai/projects/:id/apply
	‚Ä¢	‚ÄúLancer le sourcing √©co‚Äù :
	1.	POST /sourcing/discover
	2.	GET  /sourcing/project/:id/candidates
	‚Ä¢	‚ÄúCandidats unifi√©s‚Äù : GET /ai/projects/:id/candidates?diversity=true
	‚Ä¢	Conformit√© (robots.txt, whitelist, provenance), limites.

‚∏ª

8) Definition of Done
	‚Ä¢	Une annonce am√©lior√©e et standardis√©e est produite avec prix/d√©lais r√©alistes, questions manquantes, LOC uplift, persist√©s.
	‚Ä¢	Boutons/endpoints pour appliquer les suggestions (budget/d√©lais/texte) et voir les diffs.
	‚Ä¢	Sourcing √©co trouve des prestataires externes pertinents et les score ; fusion avec les candidats internes.
	‚Ä¢	Scoring global refl√®te brief_quality/richness/missing_info et explique ses d√©cisions.
	‚Ä¢	Tests unit/e2e verts, doc √† jour.

Impl√©mente tout ci‚Äëdessus, sans rien changer au syst√®me de Preview.