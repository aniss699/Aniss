ğŸ§  PROMPT REPLIT â€” Projet complet avec TOUTES les modifs dâ€™aujourdâ€™hui

(Ã€ coller tel quel dans Replit Agent / Ghostwriter)

Tu es un assistant IA fullâ€‘stack.
GÃ©nÃ¨re / mets Ã  jour un monorepo exÃ©cutable localement (Docker) pour une plateforme FR dâ€™appels dâ€™offres inversÃ©s + mise en relation payante avec : standardisation dâ€™annonces, matching & scoring explicables, enchÃ¨re inversÃ©e guidÃ©e, LOC (probabilitÃ© dâ€™aboutissement), antiâ€‘abus, sourcing web â€œmode Ã‰COâ€ (gratuit, sans clÃ©s), fusion candidats internes + externes, et intÃ©gration complÃ¨te dans lâ€™API.
Code typÃ©, testÃ©, documentÃ© (FR). Une seule commande pour lancer.

â¸»

0) ParamÃ¨tres gÃ©nÃ©raux & env
	â€¢	Langue par dÃ©faut : FR.
	â€¢	Mode Ã‰CO (gratuit) : pas dâ€™APIs payantes, dÃ©couverte via RSS/Sitemap + crawler conforme (robots.txt + rateâ€‘limit).
	â€¢	.env minimal par dÃ©faut :

OFFLINE_MODE=false
NO_EXTERNAL_CALLS=false
DOMAIN_WHITELIST="*.gouv.fr, *.insee.fr, *.cci.fr, *.pagesjaunes.fr, *.github.io, *.notion.site, *.wordpress.com"
RATE_LIMIT_GLOBAL_RPS=2
RATE_LIMIT_PER_DOMAIN_RPS=1
USER_AGENT="TestMarketplaceBot/0.1 (+contact@exemple.fr)"

FEATURE_SOURCING=true
FEATURE_API_CONNECTORS=false
FEATURE_CRAWLER=true

EMBEDDINGS_ENABLED=false
BM25_ENABLED=true


	â€¢	PossibilitÃ© future dâ€™activer des connecteurs API (Google CSE, Bing, SIRENE) via flags et clÃ©s â€” mais laisser dÃ©sactivÃ© par dÃ©faut.

â¸»

1) Structure monorepo

/apps
  /api        # Node 20, TypeScript, Fastify, Prisma (Postgres), Zod, OpenAPI, WS
  /ml         # Python 3.11, FastAPI, scikit-learn, LightGBM, (sentence-transformers local optionnel)
  /worker     # Node, BullMQ (Redis) : jobs prepare/retrain/recalc/payouts/sourcing
  /ingestion  # (NOUVEAU) sourcing web : connectors, crawler, extractors, enrichers, scoring, jobs
/packages
  /core       # TS utils: scoring multi-objectif, fairness/diversity, exposure, ingestion helpers
  /schemas    # Prisma + Zod validators
/infra
  docker-compose.yml
  init.sql
  /data       # CSV locaux (cp_city_coords.csv, taxonomy_skills_fr.csv, price_terms_fr.csv)
/tests
  unit/ (Vitest + pytest)
/tests-e2e
  e2e/ (supertest)
/tests-load
  k6/ (scÃ©narios simples)
README.md

Services Docker : api, ml, worker, ingestion (si sÃ©parÃ©), postgres, redis.
Commande unique : docker-compose up --build.

â¸»

2) SchÃ©ma DB (Prisma) â€” tables clÃ©s & ajouts
	â€¢	User(id, email unique, role:CLIENT|PRO|PERSON|ADMIN, rating_mean, rating_count, created_at)
	â€¢	ProviderProfile, ClientProfile
	â€¢	Project(â€¦ , category, quality_target, risk_tolerance, geo_required, onsite_radius_km?, status, loc_score float)
	â€¢	Bid(â€¦, amount, timeline_days, message, score_breakdown jsonb, is_leading bool, flagged bool)
	â€¢	MatchFeature, AbuseSignal, EventLog, ModelVersion

Standardisation dâ€™annonces (NOUVEAU)
	â€¢	ProjectStandardization(
project_id FK, title_std, summary_std, acceptance_criteria text[],
category_std, sub_category_std, tags_std string[],
tasks_std jsonb[], deliverables_std jsonb[],
skills_std string[], constraints_std string[],
brief_quality_score float, richness_score float,
missing_info jsonb[], price_suggested_min/med/max int,
delay_suggested_days int, loc_uplift_reco jsonb,
rewrite_version string, created_at, updated_at
)

Mise en relation (existant)
	â€¢	PersonProfile, AvailabilitySlot, Booking, IntroRequest, ContactOffer, Payment, Payout

Sourcing Web (NOUVEAU)
	â€¢	WebSource(domain unique, robots_txt jsonb, crawl_policy jsonb, last_ok_at, blocked bool)
	â€¢	WebDoc(url unique, domain, type:HOME|ABOUT|SERVICES|PORTFOLIO|PRICING|CONTACT|OTHER, title, text_summary, lang, published_at?, fetched_at, etag?, hash, source_type:RSS|SITEMAP|CRAWL, meta jsonb)
	â€¢	ExternalCompany(name, siren?, siret?, naf_code?, website?, emails[], phones[], address jsonb, city, postal_code, country, geo {lat,lng}?, social jsonb, raw_tags[], skills[], confidence float, first_seen_at, last_seen_at)
	â€¢	ExternalCompanySignal(company_id FK, kind:PRICE|AVAILABILITY|PORTFOLIO|RATING|CLAIMED, payload jsonb, score float, seen_at)
	â€¢	SourcingMatch(project_id FK, company_id FK, lead_score float, reasons jsonb, status:CANDIDATE|CONTACTED|REFUSED|CONVERTED, created_at)

Index : WebDoc.url unique, GIN jsonb sur skills/tags/meta, btree dates ; extension vector si dispo (optionnelle).

â¸»

3) Microservice ML (FastAPI, Python)

Existants Ã  maintenir
	â€¢	embedder.py (option embeddings locaux) â€” fallback BM25/TFâ€‘IDF si EMBEDDINGS_ENABLED=false
	â€¢	ranker.py : LightGBM rÃ©gressif pour GlobalScore (projetsâ†”prestataires)
	â€¢	auction.py : Price Reference Model (quantiles q25/50/75) + rÃ¨gles dâ€™enchÃ¨re (min_decrement adaptatif, nudges FR, antiâ€‘dumping/coÃ»t plancher)
	â€¢	abuse.py : IsolationForest + rÃ¨gles (BID/PROJECT/BOOKING/INTRO)
	â€¢	loc.py : LOC (projet/booking/intro) + endpoint /loc/uplift (recommandations budget/dÃ©lais)

Nouveaux pour standardisation
	â€¢	text_normalizer.py : nettoyage FR, normalisation unitÃ©s (mÂ², h, pages, km), extraction quantitÃ©s/contraintes onâ€‘site/remote
	â€¢	taxonomizer.py : mapping catÃ©gorie/sous-catÃ©gorie/skills via rÃ¨gles + BM25 (zÃ©ro clÃ©)
	â€¢	template_rewriter.py : gÃ©nÃ©ration offline (templates) title_std, summary_std, acceptance_criteria
	â€¢	brief_quality.py : brief_quality_score, richness_score, missing_info
	â€¢	price_time_suggester.py : prix min/med/max via PRM + ajustements (quality_target, onâ€‘site, market_heat, raretÃ© skills) + delay_suggested_days
	â€¢	loc_uplift.py : LOC_base, recommandations {new_budget,new_delay,delta_loc}

Endpoints ML
	â€¢	POST /standardize â†’ (normalizer + taxonomizer + rewriter + quality + price_time + loc_uplift)
	â€¢	POST /brief/recompute â†’ recalcul aprÃ¨s rÃ©ponses aux missing_info
	â€¢	(conserver) /rank, /auction/guide, /abuse/score, /loc/project|booking|intro, /pricing/intro, /rank/people

Toutes les rÃ©ponses retournent breakdown et/ou reasons[] + model_version.

â¸»

4) API (Fastify, FR)

Projets / enchÃ¨res (existant +)
	â€¢	POST /projects, GET /projects/:id, POST /projects/:id/publish
	â€¢	POST /bids, GET /projects/:id/bids
	â€¢	IA :
	â€¢	POST /ai/projects/:id/prepare
	â€¢	GET  /ai/projects/:id/price-ref â†’ {min, med, max, rationale}
	â€¢	GET  /ai/projects/:id/candidates?diversity=true â†’ topâ€‘K avec breakdown (fusion interne + sourcing)
	â€¢	POST /ai/projects/:id/auction/start
	â€¢	GET  /ai/bids/:id/explain
	â€¢	GET  /projects/:id/loc (+ ?uplift=true retourne recommandations)

Standardisation dâ€™annonce (NOUVEAU)
	â€¢	POST /ai/projects/:id/standardize â†’ crÃ©e/maj ProjectStandardization + suggestions prix/dÃ©lais + loc_uplift_reco + missing_info
	â€¢	GET  /projects/:id/standardized
	â€¢	POST /ai/projects/:id/brief/complete â†’ met Ã  jour la standardisation aprÃ¨s rÃ©ponses ; recalc scores/prix/dÃ©lais/LOC
	â€¢	GET  /ai/projects/:id/preview-scoring â†’ GlobalScore breakdown basÃ© sur la version standardisÃ©e (avant publication)

Mise en relation (existant)
	â€¢	Personnes, disponibilitÃ©s, bookings (LOC_booking) ; introductions (pricing_intro + LOC_intro)

Sourcing Web â€œMode Ã‰COâ€ (NOUVEAU)
	â€¢	POST /sourcing/discover {project_id, strategy:'rss|sitemap', max?} â†’ lance pipeline discoverâ†’fetchâ†’parseâ†’extractâ†’enrichâ†’scoreâ†’index
	â€¢	GET  /sourcing/project/:id/candidates?min_score=0.4&limit=20 â†’ ExternalCompany triÃ©es par SupplierLeadScore + reasons[]
	â€¢	GET  /sourcing/status â†’ KPIs pipeline (pages crawlÃ©es, docs valides, entreprises extraites, temps mÃ©dian, domaines bloquÃ©s)

WS
	â€¢	/ws/auction/:projectId (enchÃ¨res), /ws/schedule/:personId (agenda), /ws/intro/:personId (intros)

OpenAPI FR complet avec exemples.

â¸»

5) Scoring & intÃ©grations (packages/core)

GlobalScore (enchÃ¨res) â€” conserver + intÃ©grer standardisation :

GlobalScore = w_price*PriceScore
            + w_quality*QualityScore
            + w_fit*FitScore
            + w_time*TimeScore
            - w_risk*AbusePenalty
            + w_loc*LOCScore

	â€¢	Ajouts standardisation :

QualityScore' = QualityScore * (1 + Î»q*(brief_quality_score - 0.5))
FitScore'     = FitScore     * (1 + Î»r*(richness_score      - 0.5))
if missing_info_count > 0: Risk += 0.05 ; TimeScore -= 0.03 (penalty soft)

Par dÃ©faut Î»q=0.20, Î»r=0.15.

	â€¢	breakdown doit exposer brief_quality_adj, richness_adj, missing_info_count.

SupplierLeadScore (sourcing externes) :

SupplierLeadScore =
    w_fit*FitBM25(project_std.skills_std, company.skills)
  + w_geo*Geo(distance vs onsite_radius or remote_ok)
  + w_price*PriceAlign(company.price_signals, project.price_ref)
  + w_rep*ReputationSignal(PORTFOLIO|SERVICES dÃ©tectÃ©s)
  + w_fresh*Freshness(last_seen_at)
  - w_risk*RiskPenalty(dup/spam/incohÃ©rences)

Poids initiaux {fit .40, geo .15, price .15, rep .15, fresh .10, risk .05}.

Fusion candidats : GET /ai/projects/:id/candidates combine
(1) prestataires internes (triÃ©s par GlobalScore) et
(2) ExternalCompany (triÃ©s par SupplierLeadScore normalisÃ©),
puis diversifie via MMR si ?diversity=true.

Autres utilitaires (dÃ©jÃ  prÃ©sents ou Ã  complÃ©ter) : exposure/pacing, fairness rerank, mmrDiversify.

â¸»

6) Sourcing Web â€” pipeline (apps/ingestion)

Connectors (gratuits)
	â€¢	rss_sitemap.ts : dÃ©couverte via /sitemap.xml, /rss, /feed (sur domaines whitelistÃ©s)

Crawler conforme
	â€¢	robots.ts (respect robots.txt + cache), rate_limit.ts (global+par domaine),
	â€¢	fetcher.ts (HTTP, ETag/Last-Modified, backoff 429/503),
	â€¢	parser.ts (cheerio + Readability), normalize.ts (title/text_summary/lang/published_at/source)

Extractors
	â€¢	company_parser.ts (nom, adresse, CP/ville, email RFC, tel E.164, SIREN/SIRET regex, NAF si prÃ©sent)
	â€¢	profile_parser.ts (services/skills/portfolio/tarifs â†’ price_signals)
	â€¢	contact_parser.ts (liens social, formulaires)

Enrichers
	â€¢	geo_enricher.ts (lookup local cp_city_coords.csv â†’ lat/lng)
	â€¢	skill_inference.ts (BM25/TFâ€‘IDF vs taxonomy_skills_fr.csv)
	â€¢	price_signals.ts (â€œâ‚¬/hâ€, â€œâ‚¬/jourâ€, â€œÃ  partir deâ€, â€œforfaitâ€ â†’ range indicative)

Scoring
	â€¢	lead_scoring.ts (implÃ©mentation exacte du SupplierLeadScore + reasons[])

Job
	â€¢	jobs/discover_and_index.ts : orchestrer discoverâ†’fetchâ†’parseâ†’extractâ†’enrichâ†’scoreâ†’index (BullMQ)

â¸»

7) Standardisation â†’ dÃ©clenchement sourcing

Ã€ la fin de POST /ai/projects/:id/standardize, lancer discover_and_index avec requÃªtes formÃ©es Ã  partir de :
<category_std> <skills_std[0..2]> <ville/rÃ©gion> mais restreint aux domaines de DOMAIN_WHITELIST.
CrÃ©er SourcingMatch en CANDIDATE pour les premiÃ¨res entreprises scorÃ©es.

â¸»

8) Tests & Seeds

Seeds
	â€¢	/infra/data/ : cp_city_coords.csv, taxonomy_skills_fr.csv, price_terms_fr.csv.
	â€¢	Projets de dÃ©mo (par vertical), prestataires internes, personnes (mise en relation), bookings/intros, WebDoc dâ€™exemple (ou miniâ€‘site local simulÃ©) pour e2e.

Unit (Vitest/pytest)
	â€¢	Standardisation : normalizer/taxonomizer/template_rewriter/brief_quality/price_time/loc_uplift
	â€¢	Sourcing : robots/rateâ€‘limit/parser/BM25/geo/price_signals/lead_scoring
	â€¢	Scoring : QualityScore', FitScore', fusion candidats + MMR

E2E (supertest)
	1.	Standardiser projet â€œPeinture 40â€¯mÂ² Lyonâ€ â†’ missing_info + prix/dÃ©lais suggÃ©rÃ©s + LOC_uplift
	2.	POST /sourcing/discover (sitemap) â†’ GET /sourcing/project/:id/candidates
	3.	GET /ai/projects/:id/candidates?diversity=true (fusion internes+externes)
	4.	EnchÃ¨re guidÃ©e (antiâ€‘dumping), award
	5.	RÃ©servation/Intro (LOC_booking/LOC_intro) â€” smoke

Load (k6)
	â€¢	100 utilisateurs : standardize â†’ discover â†’ candidates â†’ bids

â¸»

9) ObservabilitÃ© & KPIs
	â€¢	/admin/metrics :
	â€¢	BriefQualityScore moyen, Delta LOC post-standardisation, Timeâ€‘toâ€‘Firstâ€‘Bid,
	â€¢	NDCG@5, Award Rate, % Winners â‰  Lowest Price,
	â€¢	Sourcing : pages crawlÃ©es, docs valides, entreprises extraites, match@K, temps mÃ©dian, domaines bloquÃ©s.
	â€¢	EventLog : tracer standardisation, sourcing, scoring, versions modÃ¨les.

â¸»

10) SÃ©curitÃ©, conformitÃ©, Ã©quitÃ©
	â€¢	robots.txt respectÃ©, DOMAIN_WHITELIST obligatoire.
	â€¢	Pas de PII sensible inutile ; toujours provenance (url, fetched_at, hash).
	â€¢	ExplicabilitÃ© : tous les scores exposent breakdown / reasons[].
	â€¢	Fairness & diversitÃ© : MMR/fairâ€‘rerank optionnels dans candidates.
	â€¢	Rateâ€‘limit + backoff + circuitâ€‘breaker par domaine.

â¸»

11) README (FR)
	â€¢	Setup .env, docker-compose up --build, routes majeures (cURL).
	â€¢	Exemple complet : standardize â†’ discover â†’ candidates (sourcing) â†’ candidates fusionnÃ©s â†’ auction.
	â€¢	Sections : â€œStandardisation dâ€™annoncesâ€, â€œSourcing web (Mode Ã‰CO)â€, â€œScoring explicableâ€, â€œLOC & upliftâ€, â€œMise en relationâ€, â€œAntiâ€‘abusâ€, â€œKPIsâ€.

â¸»

12) Definition of Done
	â€¢	Le repo se lance en 1 commande.
	â€¢	Standardisation produit titre/rÃ©sumÃ©/critÃ¨res/taxonomie/skills, prix & dÃ©lais suggÃ©rÃ©s, missing_info, LOC_uplift.
	â€¢	Sourcing web (RSS/Sitemap + crawler) retourne des ExternalCompany pertinents, scorÃ©s par SupplierLeadScore, visibles via /sourcing/project/:id/candidates.
	â€¢	Candidats IA fusionnent internes + externes dans /ai/projects/:id/candidates (MMR si demandÃ©).
	â€¢	Scoring inclut ajustements BriefQuality/Richness ; enchÃ¨re guidÃ©e avec antiâ€‘dumping ; LOC exploitÃ© (et uplift).
	â€¢	Tests unitaires & e2e â‰¥80% core, KPIs exposÃ©s, README FR clair.

GÃ©nÃ¨re/Modifie maintenant tout le code, migrations, jobs, tests et doc pour satisfaire exactement ces spÃ©cifications.